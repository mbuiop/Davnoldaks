# main.py
from flask import Flask, render_template, jsonify
from flask_cors import CORS
from flask_login import LoginManager
from flask_caching import Cache
import os
import signal
import sys
import logging
from logging.handlers import RotatingFileHandler
import multiprocessing
import threading
import time

from config import Config
from models.brain import AIBrain
from models.learning_engine import LearningEngine
from services.gemini_service import GeminiService
from services.cache_service import CacheService
from services.queue_service import QueueService
from services.file_processor import FileProcessor
from algorithms.search_engine import AdvancedSearchEngine
from api.chat_routes import chat_bp, ChatAPI
from api.admin_routes import admin_bp
from api.analytics_routes import analytics_bp
from utils.logger import setup_logger

# ================ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ================
app = Flask(__name__)
app.config.from_object(Config)
CORS(app, supports_credentials=True)

# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
Config.init_dirs()

# ================ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù„Ø§Ú¯Ø± ================
logger = setup_logger(app)

# ================ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ ================
# Ú©Ø´
cache_service = CacheService(Config)

# ØµÙ Ù¾ÛŒØ§Ù…
queue_service = QueueService(Config)

# Ø³Ø±ÙˆÛŒØ³ Ø¬Ù…ÛŒÙ†ÛŒ
gemini_service = GeminiService(Config)

# Ù…ØºØ² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
brain = AIBrain(Config)

# Ù…ÙˆØªÙˆØ± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
learning_engine = LearningEngine(Config, brain, gemini_service)

# Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬Ùˆ
search_engine = AdvancedSearchEngine(Config)

# Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± ÙØ§ÛŒÙ„
file_processor = FileProcessor(Config, brain, queue_service)

# ================ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ APIâ€ŒÙ‡Ø§ ================
# Ú†Øª
chat_api = ChatAPI(brain, gemini_service, cache_service, learning_engine, queue_service)
chat_api.register_routes(chat_bp)
app.register_blueprint(chat_bp)

# Ù…Ø¯ÛŒØ±ÛŒØª
app.register_blueprint(admin_bp)

# ØªØ­Ù„ÛŒÙ„
app.register_blueprint(analytics_bp)

# ================ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ================
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'admin.login'

from models.user import User, load_user
login_manager.user_loader(load_user)

# ================ ØµÙØ­Ø§Øª Ø§ØµÙ„ÛŒ ================
@app.route('/')
def index():
    """ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ"""
    return render_template('index.html')

@app.route('/health')
def health():
    """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…"""
    return jsonify({
        'status': 'healthy',
        'timestamp': time.time(),
        'services': {
            'redis': cache_service.redis_client.ping() if hasattr(cache_service, 'redis_client') else False,
            'queue': queue_service.get_queue_length('health') is not None,
            'gemini': gemini_service.model is not None,
            'brain': len(brain.knowledge_base) > 0
        }
    })

@app.route('/stats')
def stats():
    """Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…"""
    return jsonify({
        'knowledge': len(brain.knowledge_base),
        'users': len(learning_engine.user_patterns),
        'conversations': sum(len(p['questions']) for p in learning_engine.user_patterns.values()),
        'cache': cache_service.get_stats(),
        'queue': queue_service.get_stats(),
        'learning': learning_engine.get_learning_stats()
    })

# ================ Ù…Ø¯ÛŒØ±ÛŒØª graceful shutdown ================
def signal_handler(sig, frame):
    logger.info('Shutting down gracefully...')
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
    brain.save_knowledge()
    learning_engine.save_models()
    
    # Ø¨Ø³ØªÙ† Ø§ØªØµØ§Ù„â€ŒÙ‡Ø§
    if hasattr(cache_service, 'redis_client'):
        cache_service.redis_client.close()
        
    logger.info('Shutdown complete')
    sys.exit(0)
    
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# ================ background tasks ================
def background_learning():
    """ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡"""
    while True:
        try:
            time.sleep(300)  # Ù‡Ø± Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡
            learning_engine.learn_from_crowd()
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¬Ø³ØªØ¬Ùˆ
            if len(brain.knowledge_base) > search_engine.tfidf_matrix.shape[0]:
                search_engine.update_index(brain.knowledge_base)
                
        except Exception as e:
            logger.error(f"Background learning error: {e}")
            
def background_queue_consumer():
    """Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ ØµÙ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡"""
    def process_message(message):
        logger.info(f"Processing message: {message}")
        return True
        
    queue_service.consume('learning_tasks', process_message)
    queue_service.start_consuming()
    
# Ø´Ø±ÙˆØ¹ ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
threading.Thread(target=background_learning, daemon=True).start()
threading.Thread(target=background_queue_consumer, daemon=True).start()

# ================ Ø§Ø¬Ø±Ø§ ================
if __name__ == '__main__':
    logger.info("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘     ðŸ¤– ØªØ§Ø±ÛŒØ®â€ŒØ¯Ø§Ù† Ù‡ÙˆØ´Ù…Ù†Ø¯ - Ù†Ø³Ø®Ù‡ Enterprise Ø¨Ø§ Û± Ù…ÛŒÙ„ÛŒÙˆÙ† Ú©Ø§Ø±Ø¨Ø±   â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ðŸ“š Ø¯Ø§Ù†Ø´ ÙØ¹Ù„ÛŒ: {} Ù…ÙˆØ±Ø¯                                         â•‘
    â•‘  ðŸ‘¥ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙØ¹Ø§Ù„: {}                                           â•‘
    â•‘  ðŸ’¬ Ù…Ú©Ø§Ù„Ù…Ø§Øª: {}                                                â•‘
    â•‘  âš¡ Ú©Ø´: {} hit / {} miss ({}%)                                 â•‘
    â•‘  ðŸŽ¯ API Key: {}...                                             â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """.format(
        len(brain.knowledge_base),
        len(learning_engine.user_patterns),
        sum(len(p['questions']) for p in learning_engine.user_patterns.values()),
        cache_service.hit_count,
        cache_service.miss_count,
        cache_service.hit_count / (cache_service.hit_count + cache_service.miss_count) * 100 if (cache_service.hit_count + cache_service.miss_count) > 0 else 0,
        Config.GEMINI_API_KEY[:10]
    ))
    
    # Ø§Ø¬Ø±Ø§ Ø¨Ø§ Gunicorn
    app.run(debug=False, host='0.0.0.0', port=5000)
