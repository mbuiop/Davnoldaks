# ultimate_ai_master.py
from flask import Flask, render_template, request, jsonify, session, render_template_string, redirect, url_for, make_response
from flask_cors import CORS
from flask_login import LoginManager, UserMixin, login_user, login_required, logout_user
from werkzeug.utils import secure_filename
import hashlib
import os
import json
import re
import time
import uuid
import pickle
import threading
from datetime import datetime, timedelta
from collections import Counter, defaultdict
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import HashingVectorizer

# ================ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ================
import langid  # ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù†
from textblob import TextBlob, Word  # ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ùˆ Ú©Ù„Ù…Ø§Øª
import nltk  # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords, wordnet
from nltk.stem import WordNetLemmatizer, PorterStemmer
from nltk import pos_tag, ne_chunk  # Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù†Ù‚Ø´ Ú©Ù„Ù…Ø§Øª Ùˆ ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
import spacy  # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ù…ÛŒÙ‚ Ø²Ø¨Ø§Ù†
from collections import Counter

# ================ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ ================
import hazm  # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ
from hazm import Normalizer, WordTokenizer, SentenceTokenizer, Lemmatizer, Stemmer, POSTagger

# Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
    nltk.data.find('averaged_perceptron_tagger')
    nltk.data.find('maxent_ne_chunker')
    nltk.data.find('words')
except:
    nltk.download('punkt')
    nltk.download('stopwords')
    nltk.download('averaged_perceptron_tagger')
    nltk.download('maxent_ne_chunker')
    nltk.download('words')
    nltk.download('wordnet')

# ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ spacy (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
try:
    nlp = spacy.load("en_core_web_sm")
except:
    try:
        import subprocess
        subprocess.run(["python", "-m", "spacy", "download", "en_core_web_sm"])
        nlp = spacy.load("en_core_web_sm")
    except:
        nlp = None

app = Flask(__name__)
app.config['SECRET_KEY'] = 'super-secret-key-for-ultimate-ai'
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 200 * 1024 * 1024
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=365)
CORS(app)

# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
os.makedirs('data', exist_ok=True)
os.makedirs('uploads', exist_ok=True)
os.makedirs('memory', exist_ok=True)
os.makedirs('user_profiles', exist_ok=True)
os.makedirs('backups', exist_ok=True)

# ================ ØªØ­Ù„ÛŒÙ„Ú¯Ø± ÙÙˆÙ‚ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù…ØªÙ† ================
class UltraTextAnalyzer:
    """ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¹Ù…ÛŒÙ‚ Ù…ØªÙ† Ø¨Ø§ Û±Û°+ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…"""
    
    def __init__(self):
        # Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
        self.normalizer = Normalizer()
        self.word_tokenizer = WordTokenizer()
        self.sent_tokenizer = SentenceTokenizer()
        self.lemmatizer = Lemmatizer()
        self.stemmer = Stemmer()
        
        # Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
        self.lemmatizer_en = WordNetLemmatizer()
        self.stemmer_en = PorterStemmer()
        
        # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø³ÙˆØ§Ù„
        self.question_patterns = {
            'person': {
                'patterns': [r'(Ú©ÛŒØ³Øª|Ú©Ù‡ Ø¨ÙˆØ¯|Ú†Ù‡ Ú©Ø³ÛŒ|Ø¨ÛŒÙˆÚ¯Ø±Ø§ÙÛŒ|Ø²Ù†Ø¯Ú¯ÛŒÙ†Ø§Ù…Ù‡|Ø§ÙØ±Ø§Ø¯|Ø´Ø®Øµ|name|who|biography)'],
                'weight': 1.5
            },
            'place': {
                'patterns': [r'(Ú©Ø¬Ø§Ø³Øª|Ú©Ø¬Ø§|Ù…Ú©Ø§Ù†|Ø´Ù‡Ø±|Ú©Ø´ÙˆØ±|Ø§Ø³ØªØ§Ù†|Ù…ÙˆÙ‚Ø¹ÛŒØª|Ù…Ø­Ù„|where|location|place)'],
                'weight': 1.4
            },
            'time': {
                'patterns': [r'(Ú©ÛŒ|Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ|ØªØ§Ø±ÛŒØ®|Ø³Ø§Ù„|Ù‚Ø±Ù†|Ø¯ÙˆØ±Ù‡|Ù…ÛŒÙ„Ø§Ø¯ÛŒ|Ø´Ù…Ø³ÛŒ|Ù‡Ø¬Ø±ÛŒ|when|date|time|century)'],
                'weight': 1.4
            },
            'reason': {
                'patterns': [r'(Ú†Ø±Ø§|Ø¯Ù„ÛŒÙ„|Ø¹Ù„Øª|Ú†Ú¯ÙˆÙ†Ù‡|Ú†Ø·ÙˆØ±|Ø¨Ù‡ Ú†Ù‡ Ø¯Ù„ÛŒÙ„|why|reason|cause|how)'],
                'weight': 1.3
            },
            'definition': {
                'patterns': [r'(Ú†ÛŒØ³Øª|Ú†Ù‡ Ø¨ÙˆØ¯|ØªØ¹Ø±ÛŒÙ|ØªÙˆØ¶ÛŒØ­|Ù…Ø¹Ù†ÛŒ|Ù…ÙÙ‡ÙˆÙ…|ÛŒØ¹Ù†ÛŒ Ú†Ù‡|what|definition|meaning)'],
                'weight': 1.3
            },
            'quantity': {
                'patterns': [r'(Ú†Ù†Ø¯|ØªØ¹Ø¯Ø§Ø¯|Ù…Ù‚Ø¯Ø§Ø±|Ú†Ù‡ Ù‚Ø¯Ø±|Ú†Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡|how many|how much|quantity)'],
                'weight': 1.2
            },
            'comparison': {
                'patterns': [r'(ÙØ±Ù‚|ØªÙØ§ÙˆØª|Ø´Ø¨Ø§Ù‡Øª|Ù…Ù‚Ø§ÛŒØ³Ù‡|Ø¨Ù‡ØªØ±|Ø¨Ø¯ØªØ±|compare|comparison|difference|similar)'],
                'weight': 1.3
            },
            'code': {
                'patterns': [r'(Ú©Ø¯|Ø¨Ø±Ù†Ø§Ù…Ù‡|Ù†ÙˆÛŒØ³ÛŒ|Ù¾Ø§ÛŒØªÙˆÙ†|Ø¬Ø§ÙˆØ§|php|html|css|javascript|Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…|ØªØ§Ø¨Ø¹|code|program|function)'],
                'weight': 1.5
            },
            'alphabet': {
                'patterns': [r'(Ø­Ø±Ù|Ø§Ù„ÙØ¨Ø§|Ù†ÙˆØ´ØªÙ†|Ø§Ù…Ù„Ø§|Ø®ÙˆØ§Ù†Ø¯Ù†|ØµØ¯Ø§|Ú©Ù„Ù…Ù‡|letter|alphabet|spell|read|write)'],
                'weight': 1.4
            },
            'feeling': {
                'patterns': [r'(Ø­Ø³|Ø§Ø­Ø³Ø§Ø³|Ø¹Ø´Ù‚|Ù†ÙØ±Øª|Ø®ÙˆØ´Ø­Ø§Ù„|ØºÙ…Ú¯ÛŒÙ†|Ø¹ØµØ¨Ø§Ù†ÛŒ|happy|sad|angry|love|hate|feel)'],
                'weight': 1.6
            },
            'opinion': {
                'patterns': [r'(Ù†Ø¸Ø±|Ø¹Ù‚ÛŒØ¯Ù‡|ÙÚ©Ø±|Ø¨Ø§ÙˆØ±|ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒ|think|believe|opinion)'],
                'weight': 1.5
            }
        }
        
        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ù‡Ù…
        self.important_words = {
            'history': ['ØªØ§Ø±ÛŒØ®', 'Ù‚Ø¯ÛŒÙ…', 'Ø¨Ø§Ø³ØªØ§Ù†', 'Ù‡Ø®Ø§Ù…Ù†Ø´ÛŒ', 'Ø³Ø§Ø³Ø§Ù†ÛŒ', 'Ù‚Ø§Ø¬Ø§Ø±', 'Ù¾Ù‡Ù„ÙˆÛŒ', 'history', 'ancient'],
            'science': ['Ø¹Ù„Ù…', 'Ø¯Ø§Ù†Ø´', 'ÙÛŒØ²ÛŒÚ©', 'Ø´ÛŒÙ…ÛŒ', 'Ø²ÛŒØ³Øª', 'Ø±ÛŒØ§Ø¶ÛŒ', 'science', 'physics', 'chemistry'],
            'art': ['Ù‡Ù†Ø±', 'Ù†Ù‚Ø§Ø´ÛŒ', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ', 'Ø´Ø¹Ø±', 'Ø§Ø¯Ø¨ÛŒØ§Øª', 'art', 'music', 'painting', 'poetry'],
            'technology': ['ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ', 'Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±', 'Ø§ÛŒÙ†ØªØ±Ù†Øª', 'Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ', 'Ø±Ø¨Ø§Øª', 'technology', 'computer', 'ai'],
            'religion': ['Ø¯ÛŒÙ†', 'Ø§Ø³Ù„Ø§Ù…', 'Ù…Ø³ÛŒØ­ÛŒØª', 'ÛŒÙ‡ÙˆØ¯ÛŒØª', 'Ø²Ø±ØªØ´Øª', 'Ø®Ø¯Ø§', 'Ù¾ÛŒØ§Ù…Ø¨Ø±', 'religion', 'god', 'prophet'],
            'sport': ['ÙˆØ±Ø²Ø´', 'ÙÙˆØªØ¨Ø§Ù„', 'Ø¨Ø³Ú©ØªØ¨Ø§Ù„', 'ÙˆØ§Ù„ÛŒØ¨Ø§Ù„', 'sport', 'football', 'soccer', 'basketball'],
            'food': ['ØºØ°Ø§', 'Ø®ÙˆØ±Ø§Ú©', 'Ø¢Ø´Ù¾Ø²ÛŒ', 'Ù†Ø§Ù†', 'Ø¨Ø±Ù†Ø¬', 'food', 'cooking', 'recipe'],
            'travel': ['Ø³ÙØ±', 'Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ', 'Ù…Ø³Ø§ÙØ±Øª', 'Ù‡ØªÙ„', 'travel', 'tourism', 'hotel'],
            'education': ['Ø¢Ù…ÙˆØ²Ø´', 'Ù…Ø¯Ø±Ø³Ù‡', 'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡', 'Ú©Ù„Ø§Ø³', 'Ø¯Ø±Ø³', 'education', 'school', 'university', 'class'],
            'health': ['Ø³Ù„Ø§Ù…Øª', 'Ø¨ÛŒÙ…Ø§Ø±ÛŒ', 'Ø¯Ø±Ù…Ø§Ù†', 'Ø¯Ø§Ø±Ùˆ', 'Ø¯Ú©ØªØ±', 'health', 'disease', 'treatment', 'medicine']
        }
    
    def detect_language(self, text):
        """ØªØ´Ø®ÛŒØµ Ø¯Ù‚ÛŒÙ‚ Ø²Ø¨Ø§Ù† Ù…ØªÙ†"""
        try:
            lang, confidence = langid.classify(text)
            return lang, confidence
        except:
            # ØªØ´Ø®ÛŒØµ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ø­Ø±ÙˆÙ
            persian_chars = sum(1 for c in text if '\u0600' <= c <= '\u06FF')
            english_chars = sum(1 for c in text if 'a' <= c.lower() <= 'z')
            
            if persian_chars > english_chars:
                return 'fa', 0.8
            else:
                return 'en', 0.8
    
    def detect_question_type_deep(self, text):
        """ØªØ´Ø®ÛŒØµ Ø¹Ù…ÛŒÙ‚ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ"""
        text_lower = text.lower()
        scores = {}
        
        for q_type, data in self.question_patterns.items():
            score = 0
            for pattern in data['patterns']:
                matches = re.findall(pattern, text_lower)
                score += len(matches) * data['weight']
            if score > 0:
                scores[q_type] = score
        
        if scores:
            best_type = max(scores.items(), key=lambda x: x[1])
            return best_type[0], best_type[1]
        
        return 'general', 0
    
    def extract_keywords_advanced(self, text, top_k=10):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ ÙˆØ²Ù†"""
        # ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù†
        lang, _ = self.detect_language(text)
        
        # ØªÙˆÚ©Ù†Ø§ÛŒØ²
        if lang == 'fa':
            tokens = self.word_tokenizer.tokenize(text)
        else:
            tokens = word_tokenize(text)
        
        # Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª Ø§ÛŒØ³Øª
        stop_words = set()
        try:
            stop_words.update(stopwords.words('persian'))
        except:
            pass
        try:
            stop_words.update(stopwords.words('english'))
        except:
            pass
        
        # Ú©Ù„Ù…Ø§Øª Ù…Ù‡Ù…
        keywords = []
        for token in tokens:
            if len(token) > 2 and token.lower() not in stop_words:
                # ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ÙˆÙ‚Ø¹ÛŒØª
                weight = 1.0
                
                # Ú©Ù„Ù…Ø§Øª Ø¨Ø§ Ø­Ø±Ù Ø¨Ø²Ø±Ú¯ (Ø§Ø³Ù… Ø®Ø§Øµ)
                if token[0].isupper():
                    weight *= 1.5
                
                # Ú©Ù„Ù…Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ
                if tokens.count(token) > 1:
                    weight *= 1.3
                
                keywords.append((token, weight))
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ²Ù†
        keywords.sort(key=lambda x: x[1], reverse=True)
        return keywords[:top_k]
    
    def extract_entities(self, text):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ (Ø§Ø³Ø§Ù…ÛŒ Ø®Ø§ØµØŒ Ù…Ú©Ø§Ù†â€ŒÙ‡Ø§ØŒ ...)"""
        entities = {
            'persons': [],
            'places': [],
            'organizations': [],
            'dates': [],
            'other': []
        }
        
        # ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù†
        lang, _ = self.detect_language(text)
        
        if lang == 'en' and nlp:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² spacy Ø¨Ø±Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            doc = nlp(text)
            for ent in doc.ents:
                if ent.label_ == 'PERSON':
                    entities['persons'].append(ent.text)
                elif ent.label_ in ['GPE', 'LOC']:
                    entities['places'].append(ent.text)
                elif ent.label_ == 'ORG':
                    entities['organizations'].append(ent.text)
                elif ent.label_ == 'DATE':
                    entities['dates'].append(ent.text)
                else:
                    entities['other'].append(f"{ent.text} ({ent.label_})")
        else:
            # ØªØ´Ø®ÛŒØµ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
            words = text.split()
            for i, word in enumerate(words):
                if word[0].isupper() and len(word) > 2:
                    if i < len(words) - 1 and words[i+1][0].isupper():
                        entities['persons'].append(word + " " + words[i+1])
                    else:
                        entities['persons'].append(word)
        
        return entities
    
    def analyze_sentiment_deep(self, text):
        """ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
        try:
            blob = TextBlob(text)
            
            # Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø§ØµÙ„ÛŒ
            polarity = blob.sentiment.polarity  # -1 ØªØ§ 1
            subjectivity = blob.sentiment.subjectivity  # 0 ØªØ§ 1
            
            # ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³ Ø®Ø§Øµ
            emotion = "Ø®Ù†Ø«ÛŒ"
            if polarity > 0.5:
                emotion = "Ø¨Ø³ÛŒØ§Ø± Ù…Ø«Ø¨Øª ğŸ˜Š"
            elif polarity > 0.1:
                emotion = "Ù…Ø«Ø¨Øª ğŸ™‚"
            elif polarity < -0.5:
                emotion = "Ø¨Ø³ÛŒØ§Ø± Ù…Ù†ÙÛŒ ğŸ˜ "
            elif polarity < -0.1:
                emotion = "Ù…Ù†ÙÛŒ ğŸ˜"
            
            # Ú©Ù„Ù…Ø§Øª Ø§Ø­Ø³Ø§Ø³ÛŒ
            sentiment_words = []
            for sentence in blob.sentences:
                if abs(sentence.sentiment.polarity) > 0.3:
                    sentiment_words.append(str(sentence))
            
            return {
                'polarity': polarity,
                'subjectivity': subjectivity,
                'emotion': emotion,
                'sentiment_words': sentiment_words[:3]
            }
        except:
            return {
                'polarity': 0,
                'subjectivity': 0,
                'emotion': "Ù†Ø§Ù…Ø´Ø®Øµ",
                'sentiment_words': []
            }
    
    def get_topic(self, text):
        """ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ Ù…ØªÙ†"""
        text_lower = text.lower()
        topic_scores = {}
        
        for topic, keywords in self.important_words.items():
            score = 0
            for keyword in keywords:
                if keyword in text_lower:
                    score += 1
            if score > 0:
                topic_scores[topic] = score
        
        if topic_scores:
            return max(topic_scores.items(), key=lambda x: x[1])[0]
        
        return 'general'
    
    def analyze_context(self, text, history=None):
        """ØªØ­Ù„ÛŒÙ„ Ø²Ù…ÛŒÙ†Ù‡ Ùˆ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡"""
        context = {
            'topic': self.get_topic(text),
            'type': self.detect_question_type_deep(text)[0],
            'entities': self.extract_entities(text),
            'sentiment': self.analyze_sentiment_deep(text),
            'keywords': self.extract_keywords_advanced(text, 5),
            'language': self.detect_language(text)[0]
        }
        
        # Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡
        if history:
            # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø± Ù…ÙˆØ¶ÙˆØ¹
            same_topic_count = sum(1 for h in history if h.get('topic') == context['topic'])
            context['topic_frequency'] = same_topic_count
            
            # Ø¨Ø±Ø±Ø³ÛŒ ØªØºÛŒÛŒØ± Ø§Ø­Ø³Ø§Ø³Ø§Øª
            if history and 'sentiment' in history[-1]:
                prev_sentiment = history[-1]['sentiment'].get('polarity', 0)
                context['sentiment_change'] = context['sentiment']['polarity'] - prev_sentiment
        
        return context
    
    def calculate_similarity(self, text1, text2):
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¯Ùˆ Ù…ØªÙ†"""
        # Ø±ÙˆØ´ 1: Ø§Ø´ØªØ±Ø§Ú© Ú©Ù„Ù…Ø§Øª
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0
        
        jaccard = len(words1 & words2) / len(words1 | words2)
        
        # Ø±ÙˆØ´ 2: Ø´Ø¨Ø§Ù‡Øª Ø¨Ø±Ø¯Ø§Ø±ÛŒ (Ø³Ø§Ø¯Ù‡)
        all_words = list(words1 | words2)
        vec1 = [1 if w in words1 else 0 for w in all_words]
        vec2 = [1 if w in words2 else 0 for w in all_words]
        
        if sum(vec1) == 0 or sum(vec2) == 0:
            return jaccard
        
        dot = sum(v1 * v2 for v1, v2 in zip(vec1, vec2))
        norm1 = sum(v1 * v1 for v1 in vec1) ** 0.5
        norm2 = sum(v2 * v2 for v2 in vec2) ** 0.5
        
        cosine = dot / (norm1 * norm2) if norm1 * norm2 > 0 else 0
        
        # ØªØ±Ú©ÛŒØ¨
        return (jaccard * 0.4 + cosine * 0.6)

# ================ Ø­Ø§ÙØ¸Ù‡ Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯ ================
class InfiniteMemory:
    """Ø­Ø§ÙØ¸Ù‡ Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ù‡Ù…Ù‡ Ú†ÛŒØ²"""
    
    def __init__(self, memory_dir='memory'):
        self.memory_dir = memory_dir
        self.conversations = []
        self.user_memories = defaultdict(list)
        self.global_memory = []
        self.patterns = defaultdict(int)
        self.load_all()
    
    def load_all(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‡Ù…Ù‡ Ø®Ø§Ø·Ø±Ø§Øª"""
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ú©Ø§Ù„Ù…Ø§Øª
        conv_file = f'{self.memory_dir}/conversations.json'
        if os.path.exists(conv_file):
            with open(conv_file, 'r', encoding='utf-8') as f:
                self.conversations = json.load(f)
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§
        patterns_file = f'{self.memory_dir}/patterns.json'
        if os.path.exists(patterns_file):
            with open(patterns_file, 'r', encoding='utf-8') as f:
                self.patterns = defaultdict(int, json.load(f))
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø­Ø§ÙØ¸Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        users_file = f'{self.memory_dir}/users.json'
        if os.path.exists(users_file):
            with open(users_file, 'r', encoding='utf-8') as f:
                users_data = json.load(f)
                for uid, data in users_data.items():
                    self.user_memories[uid] = data
        
        print(f"ğŸ’¾ {len(self.conversations)} Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
        print(f"ğŸ‘¤ {len(self.user_memories)} Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ø­Ø§ÙØ¸Ù‡")
    
    def save_all(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù‡Ù…Ù‡ Ø®Ø§Ø·Ø±Ø§Øª"""
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª
        with open(f'{self.memory_dir}/conversations.json', 'w', encoding='utf-8') as f:
            json.dump(self.conversations[-10000:], f, ensure_ascii=False, indent=2)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§
        with open(f'{self.memory_dir}/patterns.json', 'w', encoding='utf-8') as f:
            json.dump(dict(self.patterns), f, ensure_ascii=False, indent=2)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø­Ø§ÙØ¸Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        with open(f'{self.memory_dir}/users.json', 'w', encoding='utf-8') as f:
            json.dump(dict(self.user_memories), f, ensure_ascii=False, indent=2)
    
    def add_conversation(self, user_id, question, answer, context):
        """Ø§ÙØ²ÙˆØ¯Ù† Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¨Ù‡ Ø­Ø§ÙØ¸Ù‡"""
        conv = {
            'id': str(uuid.uuid4())[:8],
            'user': user_id,
            'question': question,
            'answer': answer,
            'context': context,
            'time': datetime.now().isoformat()
        }
        self.conversations.append(conv)
        
        # Ø­Ø§ÙØ¸Ù‡ Ú©Ø§Ø±Ø¨Ø±
        if user_id not in self.user_memories:
            self.user_memories[user_id] = {
                'conversations': [],
                'topics': Counter(),
                'patterns': [],
                'first_seen': datetime.now().isoformat()
            }
        
        mem = self.user_memories[user_id]
        mem['conversations'].append({
            'question': question,
            'topic': context.get('topic'),
            'type': context.get('type'),
            'time': datetime.now().isoformat()
        })
        mem['topics'][context.get('topic', 'general')] += 1
        
        # Ø§Ù„Ú¯ÙˆÙ‡Ø§
        for word in context.get('keywords', []):
            if isinstance(word, tuple) and len(word) > 0:
                self.patterns[word[0]] += 1
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± Ù‡Ø± Û±Û°Û° Ù…Ú©Ø§Ù„Ù…Ù‡
        if len(self.conversations) % 100 == 0:
            self.save_all()
    
    def get_user_context(self, user_id, limit=5):
        """Ú¯Ø±ÙØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
        if user_id in self.user_memories:
            mem = self.user_memories[user_id]
            recent = mem['conversations'][-limit:]
            main_topic = mem['topics'].most_common(1)[0][0] if mem['topics'] else 'general'
            return {
                'recent': recent,
                'main_topic': main_topic,
                'total': len(mem['conversations'])
            }
        return {'recent': [], 'main_topic': 'general', 'total': 0}
    
    def find_similar_questions(self, question, analyzer, limit=5):
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡"""
        similarities = []
        for conv in self.conversations[-1000:]:  # Ø¢Ø®Ø±ÛŒÙ† Û±Û°Û°Û° ØªØ§
            sim = analyzer.calculate_similarity(question, conv['question'])
            if sim > 0.5:
                similarities.append((sim, conv['answer'], conv['context']))
        
        similarities.sort(reverse=True)
        return similarities[:limit]

# ================ Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬ÙˆÛŒ ÙÙˆÙ‚ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ================
class UltraSearchEngine:
    def __init__(self):
        self.vectorizer = TfidfVectorizer(
            max_features=20000,
            ngram_range=(1, 4),
            analyzer='char_wb',
            sublinear_tf=True,
            use_idf=True,
            smooth_idf=True
        )
        self.hashing_vectorizer = HashingVectorizer(
            n_features=2**18,  # 262144
            ngram_range=(1, 3),
            norm='l2'
        )
        self.documents = []
        self.vectors = None
        self.hashing_vectors = None
        self.analyzer = UltraTextAnalyzer()
        self.memory = InfiniteMemory()
    
    def add_document(self, question, answer, category, user_id=None):
        """Ø§ÙØ²ÙˆØ¯Ù† Ø³Ù†Ø¯ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„"""
        context = self.analyzer.analyze_context(question)
        
        doc = {
            'id': str(uuid.uuid4())[:8],
            'q': question,
            'a': answer,
            'cat': category,
            'context': context,
            'user': user_id,
            'time': datetime.now().isoformat(),
            'use_count': 0
        }
        
        self.documents.append(doc)
        return doc
    
    def update_vectors(self):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§"""
        if self.documents:
            questions = [d['q'] for d in self.documents]
            self.vectors = self.vectorizer.fit_transform(questions)
            self.hashing_vectors = self.hashing_vectorizer.transform(questions)
    
    def search_ultra(self, query, user_id=None, history=None):
        """Ø¬Ø³ØªØ¬ÙˆÛŒ ÙÙˆÙ‚ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Û· Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…"""
        # ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ø³ÙˆØ§Ù„
        query_context = self.analyzer.analyze_context(query, history)
        
        # Ú¯Ø±ÙØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ú©Ø§Ø±Ø¨Ø±
        user_context = self.memory.get_user_context(user_id) if user_id else None
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
        similar = self.memory.find_similar_questions(query, self.analyzer)
        
        results = []
        
        if not self.documents:
            return results, query_context, user_context, similar
        
        # 1. Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ø§ØµÙ„ÛŒ
        query_vec = self.vectorizer.transform([query])
        similarities = cosine_similarity(query_vec, self.vectors)[0]
        
        # 2. Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ø´ÛŒÙ†Ú¯ (Ø³Ø±ÛŒØ¹)
        query_hash = self.hashing_vectorizer.transform([query])
        hash_similarities = cosine_similarity(query_hash, self.hashing_vectors)[0]
        
        for i, doc in enumerate(self.documents):
            score = similarities[i] * 0.5 + hash_similarities[i] * 0.3
            
            # 3. ØªØ·Ø§Ø¨Ù‚ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„
            if doc['context']['type'] == query_context['type']:
                score *= 1.3
            
            # 4. ØªØ·Ø§Ø¨Ù‚ Ù…ÙˆØ¶ÙˆØ¹
            if doc['context']['topic'] == query_context['topic']:
                score *= 1.2
            
            # 5. Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø´ØªØ±Ú©
            doc_keywords = [k[0] for k in doc['context'].get('keywords', [])]
            query_keywords = [k[0] for k in query_context.get('keywords', [])]
            common = set(doc_keywords) & set(query_keywords)
            if common:
                score *= (1 + len(common) * 0.1)
            
            # 6. ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±
            if user_context and user_context['main_topic'] == doc['context']['topic']:
                score *= 1.1
            
            # 7. ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡
            for sim_score, sim_answer, sim_context in similar:
                if sim_answer == doc['a']:
                    score *= (1 + sim_score * 0.2)
            
            if score > 0.15:
                results.append({
                    'answer': doc['a'],
                    'score': float(score),
                    'category': doc['cat'],
                    'context': doc['context']
                })
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
        results.sort(key=lambda x: x['score'], reverse=True)
        
        # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡
        if results and len(self.documents) > 0:
            for doc in self.documents:
                if doc['a'] == results[0]['answer']:
                    doc['use_count'] += 1
                    break
        
        return results[:5], query_context, user_context, similar

# ================ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§ØµÙ„ÛŒ ================
class UltimateAI:
    def __init__(self):
        self.search = UltraSearchEngine()
        self.analyzer = UltraTextAnalyzer()
        self.memory = InfiniteMemory()
        self.db_file = 'data/ultimate_knowledge.json'
        self.load_knowledge()
        
        print(f"âœ… {len(self.search.documents)} Ø¯Ø§Ù†Ø´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
        print(f"ğŸ’¾ {len(self.memory.conversations)} Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡")
    
    def load_knowledge(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ù†Ø´"""
        if os.path.exists(self.db_file):
            with open(self.db_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for item in data:
                    doc = self.search.add_document(
                        item['q'], 
                        item['a'], 
                        item.get('cat', 'general'),
                        item.get('user')
                    )
        
        self.search.update_vectors()
    
    def save_knowledge(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ù†Ø´"""
        data = []
        for doc in self.search.documents:
            data.append({
                'id': doc['id'],
                'q': doc['q'],
                'a': doc['a'],
                'cat': doc['cat'],
                'user': doc.get('user'),
                'time': doc.get('time')
            })
        
        with open(self.db_file, 'w', encoding='utf-8') as f:
            json.dump(data[-10000:], f, ensure_ascii=False, indent=2)
    
    def learn(self, question, answer, category='general', user_id=None):
        """ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ù†Ø´ Ø¬Ø¯ÛŒØ¯"""
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
        question = self.analyzer.normalizer.normalize(question) if hasattr(self.analyzer, 'normalizer') else question
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
        for doc in self.search.documents:
            if self.analyzer.calculate_similarity(doc['q'], question) > 0.9:
                doc['a'] = answer
                doc['use_count'] = doc.get('use_count', 0) + 1
                self.save_knowledge()
                return True, "Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¬Ø¯ÛŒØ¯
        self.search.add_document(question, answer, category, user_id)
        self.search.update_vectors()
        self.save_knowledge()
        
        return True, "ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯"
    
    def ask(self, question, user_id=None, history=None):
        """Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯"""
        results, query_context, user_context, similar = self.search.search_ultra(question, user_id, history)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
        if results:
            best = results[0]
            self.memory.add_conversation(user_id, question, best['answer'], query_context)
            
            # Ø³Ø§Ø®Øª Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯
            answer = best['answer']
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…ÛŒÙ†Ù‡
            if query_context['topic'] == 'history' and 'sentiment' in query_context:
                if query_context['sentiment']['polarity'] > 0.3:
                    answer += "\n\nğŸ“š Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ø¨Ù‡ ØªØ§Ø±ÛŒØ® Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±ÛŒØ¯!"
                elif query_context['sentiment']['polarity'] < -0.3:
                    answer += "\n\nğŸ˜” ØªØ§Ø±ÛŒØ® Ù¾Ø± Ø§Ø² ÙØ±Ø§Ø² Ùˆ Ù†Ø´ÛŒØ¨ Ø§Ø³Øª..."
            
            # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø³ÙˆØ§Ù„ Ù…Ø´Ø§Ø¨Ù‡ Ù¾Ø±Ø³ÛŒØ¯Ù‡
            if user_context and user_context['total'] > 5:
                if user_context['main_topic'] == query_context['topic']:
                    answer += f"\n\nâœ¨ Ø´Ù…Ø§ {user_context['total']} Ø¨Ø§Ø± Ø¯Ø±Ø¨Ø§Ø±Ù‡ {query_context['topic']} Ø³ÙˆØ§Ù„ Ù¾Ø±Ø³ÛŒØ¯Ù‡â€ŒØ§ÛŒØ¯!"
            
            return {
                'answer': answer,
                'context': query_context,
                'found': True
            }
        else:
            # Ø«Ø¨Øª Ø³ÙˆØ§Ù„ Ø¨ÛŒâ€ŒÙ¾Ø§Ø³Ø®
            self.memory.add_conversation(user_id, question, None, query_context)
            
            # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„
            suggestion = ""
            if query_context['type'] != 'general':
                suggestion = f"\n\nğŸ’¡ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§ Ø§Ø² Ù†ÙˆØ¹ '{query_context['type']}' Ø§Ø³Øª. Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÙˆØ§Ø¶Ø­â€ŒØªØ± Ø¨Ù¾Ø±Ø³ÛŒØ¯."
            
            return {
                'answer': None,
                'context': query_context,
                'suggestion': suggestion,
                'found': False
            }
    
    def get_stats(self):
        """Ú¯Ø±ÙØªÙ† Ø¢Ù…Ø§Ø±"""
        return {
            'knowledge': len(self.search.documents),
            'conversations': len(self.memory.conversations),
            'users': len(self.memory.user_memories),
            'patterns': len(self.memory.patterns)
        }

# ================ Ù†Ù…ÙˆÙ†Ù‡ Ø§ØµÙ„ÛŒ ================
ai = UltimateAI()

# ================ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ================
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'admin_login'

class User(UserMixin):
    def __init__(self, id, username, password):
        self.id = id
        self.username = username
        self.password = password

users = {'1': User('1', 'admin', hashlib.md5('admin123'.encode()).hexdigest())}

@login_manager.user_loader
def load_user(user_id):
    return users.get(user_id)

# ================ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ú†Øª ================
@app.route('/')
def index():
    user_id = request.cookies.get('user_id')
    if not user_id:
        user_id = str(uuid.uuid4())
    
    # Ú¯Ø±ÙØªÙ† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ø²Ù…ÛŒÙ†Ù‡
    user_context = ai.memory.get_user_context(user_id)
    
    resp = make_response(render_template_string('''
    <!DOCTYPE html>
    <html lang="fa" dir="rtl">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙÙˆÙ‚ Ù¾ÛŒØ´Ø±ÙØªÙ‡</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body {
                font-family: 'Vazir', 'Tahoma', sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                height: 100vh;
                display: flex;
                align-items: center;
                justify-content: center;
                padding: 10px;
            }
            .chat-container {
                width: 100%;
                max-width: 500px;
                height: 95vh;
                background: white;
                border-radius: 30px;
                box-shadow: 0 25px 50px rgba(0,0,0,0.3);
                display: flex;
                flex-direction: column;
                overflow: hidden;
            }
            .chat-header {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 15px 20px;
                display: flex;
                align-items: center;
                justify-content: space-between;
            }
            .menu-btn {
                background: none;
                border: none;
                color: white;
                font-size: 28px;
                cursor: pointer;
                width: 44px;
                height: 44px;
            }
            .header-title {
                font-size: 1.3em;
                font-weight: bold;
            }
            .chat-messages {
                flex: 1;
                overflow-y: auto;
                padding: 20px;
                background: #f8fafc;
                display: flex;
                flex-direction: column;
                gap: 15px;
            }
            .message {
                display: flex;
                animation: slideIn 0.3s ease;
            }
            @keyframes slideIn {
                from { opacity: 0; transform: translateY(10px); }
                to { opacity: 1; transform: translateY(0); }
            }
            .message.user { justify-content: flex-end; }
            .message.bot { justify-content: flex-start; }
            .message-content {
                max-width: 85%;
                padding: 14px 18px;
                border-radius: 25px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
                line-height: 1.6;
                word-wrap: break-word;
            }
            .user .message-content {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                border-bottom-right-radius: 5px;
            }
            .bot .message-content {
                background: white;
                border-bottom-left-radius: 5px;
            }
            .message-time {
                font-size: 0.7em;
                opacity: 0.7;
                margin-top: 5px;
            }
            .typing-indicator {
                padding: 14px 20px;
                background: white;
                border-radius: 25px;
                display: inline-block;
            }
            .typing-indicator span {
                display: inline-block;
                width: 8px;
                height: 8px;
                border-radius: 50%;
                background: #667eea;
                margin: 0 3px;
                animation: typing 1.4s infinite;
            }
            @keyframes typing {
                0%, 60%, 100% { transform: translateY(0); }
                30% { transform: translateY(-10px); }
            }
            .chat-input-container {
                padding: 15px 20px;
                background: white;
                border-top: 1px solid #eee;
                display: flex;
                gap: 10px;
            }
            .chat-input {
                flex: 1;
                padding: 14px 18px;
                border: 2px solid #e0e0e0;
                border-radius: 30px;
                font-size: 1rem;
                outline: none;
                font-family: inherit;
            }
            .chat-input:focus {
                border-color: #667eea;
            }
            .send-btn {
                width: 52px;
                height: 52px;
                border-radius: 50%;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                border: none;
                cursor: pointer;
                font-size: 1.4em;
            }
            .menu-panel {
                position: fixed;
                top: 0;
                right: -300px;
                width: 280px;
                height: 100%;
                background: white;
                transition: right 0.3s ease;
                box-shadow: -5px 0 30px rgba(0,0,0,0.2);
                padding: 20px;
                z-index: 1001;
            }
            .menu-panel.open { right: 0; }
            .menu-overlay {
                position: fixed;
                top: 0;
                left: 0;
                right: 0;
                bottom: 0;
                background: rgba(0,0,0,0.5);
                display: none;
                z-index: 1000;
            }
            .menu-item {
                padding: 15px;
                margin: 5px 0;
                border-radius: 15px;
                cursor: pointer;
                display: flex;
                align-items: center;
                gap: 15px;
                text-decoration: none;
                color: #333;
            }
            .menu-item:hover { background: #f0f2f5; }
        </style>
    </head>
    <body>
        <div class="chat-container">
            <div class="chat-header">
                <button class="menu-btn" onclick="toggleMenu()">â˜°</button>
                <div class="header-title">ğŸ¤– Ù‡ÙˆØ´ ÙÙˆÙ‚ Ù¾ÛŒØ´Ø±ÙØªÙ‡</div>
                <div style="width:44px;"></div>
            </div>
            
            <div class="chat-messages" id="chat-messages">
                <div class="message bot">
                    <div class="message-content">
                        Ø³Ù„Ø§Ù…! Ù…Ù† Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‡Ø³ØªÙ…. Ù‡Ø± Ø³ÙˆØ§Ù„ÛŒ Ø¯Ø§Ø±ÛŒ Ø¨Ù¾Ø±Ø³ØŒ Ù…Ù† ØªÙˆ Ø±Ùˆ Ø¯Ø±Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù…!
                        <div class="message-time">{{ now }}</div>
                    </div>
                </div>
            </div>
            
            <div class="chat-input-container">
                <input type="text" class="chat-input" id="message-input" 
                       placeholder="Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯..." 
                       onkeypress="if(event.key==='Enter') sendMessage()">
                <button class="send-btn" onclick="sendMessage()">â¤</button>
            </div>
        </div>
        
        <div class="menu-overlay" id="menuOverlay" onclick="closeMenu()"></div>
        <div class="menu-panel" id="menuPanel">
            <h3 style="margin-bottom:20px;">ğŸ“‹ Ù…Ù†Ùˆ</h3>
            <a href="/m.html" class="menu-item">ğŸ“„ ØµÙØ­Ù‡ M</a>
            <a href="/admin-login" class="menu-item">âš™ï¸ Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª</a>
            <div class="menu-item" onclick="clearHistory()">ğŸ—‘ï¸ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡</div>
            <div style="margin-top:20px; font-size:0.9em; color:#666;">
                <p>ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù…Ú©Ø§Ù„Ù…Ø§Øª: {{ user_total }}</p>
                <p>ğŸ¯ Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ: {{ user_topic }}</p>
            </div>
        </div>
        
        <script>
            let chatHistory = JSON.parse(localStorage.getItem('chat_history')) || [];
            let userHistory = [];
            
            chatHistory.forEach(msg => {
                addMessage(msg.text, msg.isUser, msg.time, false);
            });
            
            function toggleMenu() {
                document.getElementById('menuOverlay').style.display = 'block';
                document.getElementById('menuPanel').classList.add('open');
            }
            
            function closeMenu() {
                document.getElementById('menuOverlay').style.display = 'none';
                document.getElementById('menuPanel').classList.remove('open');
            }
            
            function addMessage(text, isUser = false, time = null, save = true) {
                const div = document.createElement('div');
                div.className = `message ${isUser ? 'user' : 'bot'}`;
                
                const msgTime = time || new Date().toLocaleTimeString('fa-IR');
                
                div.innerHTML = `
                    <div class="message-content">
                        ${text.replace(/\\n/g, '<br>')}
                        <div class="message-time">${msgTime}</div>
                    </div>
                `;
                
                document.getElementById('chat-messages').appendChild(div);
                div.scrollIntoView({ behavior: 'smooth' });
                
                if (save) {
                    userHistory.push({ text, isUser });
                    chatHistory.push({ text, isUser, time: msgTime });
                    if (chatHistory.length > 100) chatHistory = chatHistory.slice(-100);
                    localStorage.setItem('chat_history', JSON.stringify(chatHistory));
                }
            }
            
            function showTyping() {
                const div = document.createElement('div');
                div.className = 'message bot';
                div.id = 'typing';
                div.innerHTML = '<div class="typing-indicator"><span></span><span></span><span></span></div>';
                document.getElementById('chat-messages').appendChild(div);
                div.scrollIntoView({ behavior: 'smooth' });
            }
            
            function hideTyping() {
                const typing = document.getElementById('typing');
                if (typing) typing.remove();
            }
            
            async function sendMessage() {
                const input = document.getElementById('message-input');
                const message = input.value.trim();
                if (!message) return;
                
                addMessage(message, true);
                input.value = '';
                showTyping();
                
                try {
                    const response = await fetch('/api/chat', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({
                            message,
                            history: userHistory.slice(-5)
                        })
                    });
                    
                    const data = await response.json();
                    hideTyping();
                    
                    if (data.answer) {
                        addMessage(data.answer);
                    } else {
                        let msg = 'ğŸ¤” Ù…ØªØ£Ø³ÙÙ…! Ù†ØªÙˆÙ†Ø³ØªÙ… Ù¾ÛŒØ¯Ø§ Ú©Ù†Ù….';
                        if (data.suggestion) msg += data.suggestion;
                        addMessage(msg);
                    }
                    
                } catch (error) {
                    hideTyping();
                    addMessage('âš ï¸ Ø®Ø·Ø§');
                }
            }
            
            function clearHistory() {
                if (confirm('Ù¾Ø§Ú© Ø´ÙˆØ¯ØŸ')) {
                    localStorage.removeItem('chat_history');
                    chatHistory = [];
                    userHistory = [];
                    location.reload();
                }
            }
        </script>
    </body>
    </html>
    ''', now=datetime.now().strftime('%H:%M'), 
        user_total=user_context['total'], 
        user_topic=user_context['main_topic']))
    
    resp.set_cookie('user_id', user_id, max_age=365*24*60*60)
    return resp

@app.route('/m.html')
def m_page():
    return '''
    <!DOCTYPE html>
    <html>
    <head><title>ØµÙØ­Ù‡ M</title>
    <style>body{font-family:Tahoma;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);min-height:100vh;display:flex;align-items:center;justify-content:center;padding:20px;}.container{background:white;border-radius:30px;padding:40px;max-width:600px;text-align:center;}.btn{display:inline-block;padding:15px 40px;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:white;text-decoration:none;border-radius:30px;margin-top:20px;}</style>
    </head>
    <body><div class="container"><h1>ğŸ“„ ØµÙØ­Ù‡ M</h1><p>ØµÙØ­Ù‡ Ù…Ø®ØµÙˆØµ Ù…Ù†Ùˆ</p><a href="/" class="btn">Ø¨Ø§Ø²Ú¯Ø´Øª</a></div></body>
    </html>
    '''

@app.route('/api/chat', methods=['POST'])
def api_chat():
    try:
        data = request.json
        question = data.get('message', '').strip()
        history = data.get('history', [])
        user_id = request.cookies.get('user_id')
        
        if not question:
            return jsonify({'error': 'Ø³ÙˆØ§Ù„ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª'})
        
        result = ai.ask(question, user_id, history)
        
        if result['found']:
            return jsonify({
                'answer': result['answer'],
                'found': True
            })
        else:
            return jsonify({
                'answer': None,
                'suggestion': result.get('suggestion', ''),
                'found': False
            })
            
    except Exception as e:
        return jsonify({'error': str(e)})

# ================ Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª ================
@app.route('/admin-login', methods=['GET', 'POST'])
def admin_login():
    if request.method == 'POST':
        username = request.form['username']
        password = hashlib.md5(request.form['password'].encode()).hexdigest()
        
        if username == 'admin' and password == hashlib.md5('admin123'.encode()).hexdigest():
            login_user(users['1'])
            return redirect(url_for('admin_panel'))
        
        return "âŒ Ø±Ù…Ø² Ø§Ø´ØªØ¨Ø§Ù‡"
    
    return '''
    <!DOCTYPE html>
    <html>
    <head><title>ÙˆØ±ÙˆØ¯</title>
    <style>body{font-family:Tahoma;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);height:100vh;display:flex;align-items:center;justify-content:center;}.login-box{background:white;padding:40px;border-radius:30px;width:400px;}input,button{width:100%;padding:15px;margin:10px 0;border-radius:15px;border:2px solid #e0e0e0;}button{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:white;border:none;cursor:pointer;}</style>
    </head>
    <body><div class="login-box"><h2>ğŸ” ÙˆØ±ÙˆØ¯</h2><form method="POST"><input name="username" value="admin"><input name="password" type="password" value="admin123"><button type="submit">ÙˆØ±ÙˆØ¯</button></form></div></body>
    </html>
    '''

@app.route('/admin')
@login_required
def admin_panel():
    stats = ai.get_stats()
    
    return f'''
    <!DOCTYPE html>
    <html>
    <head><title>Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª</title>
    <style>
        *{{margin:0;padding:0;box-sizing:border-box;}}
        body{{font-family:Tahoma;background:#f5f5f5;padding:20px;}}
        .header{{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:white;padding:20px;border-radius:15px;margin-bottom:20px;display:flex;justify-content:space-between;}}
        .stats-grid{{display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:15px;margin-bottom:20px;}}
        .stat-card{{background:white;padding:20px;border-radius:15px;text-align:center;}}
        .stat-number{{font-size:2.5em;color:#667eea;font-weight:bold;}}
        .card{{background:white;padding:20px;border-radius:15px;margin-bottom:20px;}}
        textarea,input,select{{width:100%;padding:12px;margin:10px 0;border:2px solid #e0e0e0;border-radius:10px;}}
        button{{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:white;padding:12px 25px;border:none;border-radius:10px;cursor:pointer;}}
    </style>
    </head>
    <body>
        <div class="header">
            <h2>âš™ï¸ Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´ ÙÙˆÙ‚ Ù¾ÛŒØ´Ø±ÙØªÙ‡</h2>
            <div>
                <a href="/" style="color:white;margin-right:15px;">ğŸ  Ú†Øª</a>
                <a href="/logout" style="color:white;">ğŸšª Ø®Ø±ÙˆØ¬</a>
            </div>
        </div>
        
        <div class="stats-grid">
            <div class="stat-card"><div class="stat-number">{stats['knowledge']}</div><div>Ø¯Ø§Ù†Ø´</div></div>
            <div class="stat-card"><div class="stat-number">{stats['conversations']}</div><div>Ù…Ú©Ø§Ù„Ù…Ø§Øª</div></div>
            <div class="stat-card"><div class="stat-number">{stats['users']}</div><div>Ú©Ø§Ø±Ø¨Ø±Ø§Ù†</div></div>
            <div class="stat-card"><div class="stat-number">{stats['patterns']}</div><div>Ø§Ù„Ú¯ÙˆÙ‡Ø§</div></div>
        </div>
        
        <div class="card">
            <h3>ğŸ“ Ø¢Ù…ÙˆØ²Ø´</h3>
            <form action="/admin/learn" method="POST">
                <input type="text" name="question" placeholder="Ø³ÙˆØ§Ù„" required>
                <textarea name="answer" rows="3" placeholder="Ù¾Ø§Ø³Ø®" required></textarea>
                <select name="category">
                    <option value="general">Ø¹Ù…ÙˆÙ…ÛŒ</option>
                    <option value="history">ØªØ§Ø±ÛŒØ®</option>
                    <option value="science">Ø¹Ù„Ù…ÛŒ</option>
                    <option value="code">Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ</option>
                </select>
                <button type="submit">ğŸ“š ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±</button>
            </form>
        </div>
        
        <div class="card">
            <h3>ğŸ“ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„</h3>
            <form action="/admin/learn/file" method="POST" enctype="multipart/form-data">
                <input type="file" name="file" accept=".txt" required>
                <button type="submit">ğŸ“¤ Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ</button>
            </form>
        </div>
    </body>
    </html>
    '''

@app.route('/admin/learn', methods=['POST'])
@login_required
def learn():
    q = request.form['question']
    a = request.form['answer']
    cat = request.form.get('category', 'general')
    ai.learn(q, a, cat)
    return redirect(url_for('admin_panel'))

@app.route('/admin/learn/file', methods=['POST'])
@login_required
def learn_file():
    try:
        file = request.files['file']
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        count = 0
        for line in content.split('\n'):
            if '|' in line:
                q, a = line.split('|', 1)
                ai.learn(q.strip(), a.strip())
                count += 1
        
        os.remove(filepath)
        return f"âœ… {count} Ù…ÙˆØ±Ø¯ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯<br><a href='/admin'>Ø¨Ø§Ø²Ú¯Ø´Øª</a>"
    except Exception as e:
        return f"âŒ Ø®Ø·Ø§: {str(e)}<br><a href='/admin'>Ø¨Ø§Ø²Ú¯Ø´Øª</a>"

@app.route('/logout')
@login_required
def logout():
    logout_user()
    return redirect(url_for('index'))

if __name__ == '__main__':
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘     ğŸ¤– Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙÙˆÙ‚ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ù…ØªÙ†             â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ğŸ“š Ø¯Ø§Ù†Ø´: {}                                                    â•‘
    â•‘  ğŸ’¾ Ù…Ú©Ø§Ù„Ù…Ø§Øª: {}                                                 â•‘
    â•‘  ğŸ‘¤ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {}                                                 â•‘
    â•‘  ğŸ” Û· Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¬Ø³ØªØ¬Ùˆ + ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª + ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¬ÙˆØ¯ÛŒØª        â•‘
    â•‘  ğŸŒ Ú†Øª: http://localhost:5000                                 â•‘
    â•‘  ğŸ” Ù¾Ù†Ù„: http://localhost:5000/admin-login                    â•‘
    â•‘  ğŸ‘¤ Ú©Ø§Ø±Ø¨Ø±: admin / admin123                                    â•‘
    â•‘  ğŸ’¡ Ø­Ø§ÙØ¸Ù‡ Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯ + ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ú©Ø§Ù„Ù…Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†                â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """.format(ai.get_stats()['knowledge'], ai.get_stats()['conversations'], ai.get_stats()['users']))
    
    app.run(debug=True, host='0.0.0.0', port=5000)
